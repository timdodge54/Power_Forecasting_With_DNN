{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def PrecipTypeToVal(precip_type):\n",
    "    if precip_type == 'rain':\n",
    "        return 0\n",
    "    elif precip_type == 'snow':\n",
    "        return 1\n",
    "    else:\n",
    "        raise RuntimeError('that is not a good precip type')\n",
    "    \n",
    "def ValToPrecipType(precip_type):\n",
    "    if precip_type == 0:\n",
    "        return 'rain'\n",
    "    elif precip_type == 1:\n",
    "        return 'snow'\n",
    "    else:\n",
    "        raise RuntimeError('that is not a good precip type value')\n",
    "\n",
    "def getData(data_dir = '../data/'):\n",
    "    # Load data \n",
    "    holidays_df       = pd.read_csv(data_dir + 'uk_bank_holidays.csv')\n",
    "    weather_hourly_df = pd.read_csv(data_dir + 'weather_hourly_darksky.csv')\n",
    "    by_meter_df       = pd.read_csv(data_dir + 'informations_households.csv')\n",
    "\n",
    "    half_hour_power_df = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_0.csv\")\n",
    "    for block_it in range(1,112):\n",
    "        half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
    "        half_hour_power_df = pd.concat([half_hour_power_block], ignore_index=True)\n",
    "    holidays_df = holidays_df.drop('Type', axis=1)\n",
    "    holidays_df['Bank holidays'] = pd.to_datetime(holidays_df['Bank holidays'], format='%Y-%m-%d', utc=True)\n",
    "    weather_hourly_df = weather_hourly_df.rename(columns={\"time\": \"timestamp\"})\n",
    "    weather_hourly_df = weather_hourly_df.drop(['icon', 'windBearing', 'apparentTemperature', 'summary'], axis=1)\n",
    "    weather_hourly_df['timestamp'] = pd.to_datetime(weather_hourly_df['timestamp'], utc=True)\n",
    "    by_meter_df = by_meter_df.drop(['stdorToU', 'Acorn', 'file'], axis=1)\n",
    "    half_hour_power_df = half_hour_power_df.rename(columns={\"tstp\": \"timestamp\"})\n",
    "    half_hour_power_df['timestamp'] = pd.to_datetime(half_hour_power_df['timestamp'], utc=True)\n",
    "    half_hour_power_df = half_hour_power_df[half_hour_power_df['energy(kWh/hh)'] != 'Null']\n",
    "    half_hour_power_df['energy(kWh/hh)'] = half_hour_power_df['energy(kWh/hh)'].astype('float')\n",
    "\n",
    "    # Get time vec\n",
    "    weather_hourly_df = weather_hourly_df.sort_values(by='timestamp')\n",
    "    start_time = weather_hourly_df['timestamp'].iloc[0]\n",
    "    end_time = weather_hourly_df['timestamp'].iloc[-1]\n",
    "    iterated_time = start_time + timedelta(minutes=30)\n",
    "    all_needed_times = [copy.deepcopy(iterated_time)]\n",
    "    while iterated_time < end_time:\n",
    "        iterated_time = iterated_time + timedelta(minutes=30)\n",
    "        all_needed_times.append(copy.deepcopy(iterated_time))\n",
    "    time_df = pd.DataFrame({'timestamp': all_needed_times})\n",
    "\n",
    "    # Interpolate weather data\n",
    "    weather_half_hour_df = pd.merge(time_df, weather_hourly_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df.sort_values(by='timestamp', inplace=True)\n",
    "    weather_half_hour_df['precipType'].fillna(method='ffill', inplace=True)\n",
    "    weather_half_hour_df['precipType'].fillna(method='bfill', inplace=True)\n",
    "    for col_it in ['temperature', 'dewPoint', 'pressure', 'windSpeed', 'humidity', 'visibility']:\n",
    "        weather_half_hour_df[col_it].interpolate(method='quadratic', inplace=True)\n",
    "        weather_half_hour_df[col_it].fillna(method='ffill', inplace=True)\n",
    "        weather_half_hour_df[col_it].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Replace precipType with index values\n",
    "    weather_half_hour_df['precipType'] = weather_half_hour_df['precipType'].apply(lambda x: PrecipTypeToVal(x))\n",
    "\n",
    "    # Add holidays \n",
    "    weather_half_hour_df = weather_half_hour_df.merge(holidays_df, left_on = 'timestamp', right_on = 'Bank holidays', how = 'left')\n",
    "    weather_half_hour_df['Bank holidays'] = np.where(weather_half_hour_df['Bank holidays'].isna(), 0, 1)\n",
    "\n",
    "    # Put it all together\n",
    "    housecount   = half_hour_power_df.groupby('timestamp')[['LCLid']].nunique().sort_values(by='timestamp').astype('float')\n",
    "    total_energy = half_hour_power_df.groupby('timestamp')[['energy(kWh/hh)']].sum().sort_values(by='timestamp').astype('float')\n",
    "\n",
    "    weather_half_hour_df = pd.merge(housecount, weather_half_hour_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df = weather_half_hour_df.rename(columns={\"LCLid\": \"num_houses\"})\n",
    "    \n",
    "    weather_half_hour_df = pd.merge(total_energy, weather_half_hour_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df = weather_half_hour_df.rename(columns={\"energy(kWh/hh)\": \"total_energy\"})\n",
    "    \n",
    "    weather_half_hour_df.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "\n",
    "    output = pd.DataFrame(data={'timestamp': weather_half_hour_df['timestamp'],\n",
    "                                'avg_energy': weather_half_hour_df['total_energy'] / weather_half_hour_df['num_houses'],\n",
    "                                'num_houses': weather_half_hour_df['num_houses'],\n",
    "                                'is_holiday': weather_half_hour_df['Bank holidays'],\n",
    "                                'visibility': weather_half_hour_df['visibility'],\n",
    "                                'temperature': weather_half_hour_df['temperature'],\n",
    "                                'dewPoint': weather_half_hour_df['dewPoint'],\n",
    "                                'pressure': weather_half_hour_df['pressure'],\n",
    "                                'windSpeed': weather_half_hour_df['windSpeed'],\n",
    "                                'precipType': weather_half_hour_df['precipType'],\n",
    "                                'humidity': weather_half_hour_df['humidity']})\n",
    "    output.dropna(axis=0, inplace=True)\n",
    "\n",
    "    # Normalize \n",
    "    normalization_cols = [i for i in output.columns.tolist() if i not in ['timestamp', 'precipType', 'num_houses', 'is_holiday']]\n",
    "    normalization_vals = {}\n",
    "    for col_name in normalization_cols:\n",
    "        normalization_vals[col_name] = {}\n",
    "        normalization_vals[col_name]['min'] = output[col_name].min()\n",
    "        normalization_vals[col_name]['max'] = output[col_name].max()\n",
    "        normalization_vals[col_name]['std'] = output[col_name].std()\n",
    "    normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "    output[normalization_cols] = normalizer.fit_transform(output[normalization_cols])\n",
    "\n",
    "    return output, normalization_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                      timestamp  avg_energy  num_houses  is_holiday  \\\n",
       " 0     2011-12-21 09:30:00+00:00    0.145889         1.0           0   \n",
       " 1     2011-12-21 10:00:00+00:00    0.074271         1.0           0   \n",
       " 2     2011-12-21 10:30:00+00:00    0.052387         1.0           0   \n",
       " 3     2011-12-21 11:00:00+00:00    0.086207         1.0           0   \n",
       " 4     2011-12-21 11:30:00+00:00    0.044430         1.0           0   \n",
       " ...                         ...         ...         ...         ...   \n",
       " 38377 2014-02-27 22:00:00+00:00    0.353102        46.0           0   \n",
       " 38378 2014-02-27 22:30:00+00:00    0.321085        46.0           0   \n",
       " 38379 2014-02-27 23:00:00+00:00    0.318793        46.0           0   \n",
       " 38380 2014-02-27 23:30:00+00:00    0.231908        46.0           0   \n",
       " 38381 2014-02-28 00:00:00+00:00    0.170410        46.0           0   \n",
       " \n",
       "        visibility  temperature  dewPoint  pressure  windSpeed  precipType  \\\n",
       " 0        0.384568     0.388128  0.630449  0.601988   0.233267           0   \n",
       " 1        0.491921     0.399211  0.648694  0.608197   0.247295           0   \n",
       " 2        0.550352     0.412846  0.656954  0.614128   0.244879           0   \n",
       " 3        0.588649     0.424932  0.662090  0.618994   0.238609           0   \n",
       " 4        0.635596     0.431366  0.670963  0.622007   0.241075           0   \n",
       " ...           ...          ...       ...       ...        ...         ...   \n",
       " 38377    0.847610     0.255642  0.389149  0.443133   0.201194           0   \n",
       " 38378    0.843370     0.251805  0.388935  0.435741   0.193313           0   \n",
       " 38379    0.849446     0.251180  0.388145  0.427603   0.183154           0   \n",
       " 38380    0.808383     0.250244  0.387023  0.419580   0.175031           0   \n",
       " 38381    0.763738     0.248030  0.385466  0.412073   0.168455           0   \n",
       " \n",
       "        humidity  \n",
       " 0      0.968823  \n",
       " 1      0.979768  \n",
       " 2      0.954922  \n",
       " 3      0.928201  \n",
       " 4      0.933520  \n",
       " ...         ...  \n",
       " 38377  0.786392  \n",
       " 38378  0.798160  \n",
       " 38379  0.799284  \n",
       " 38380  0.797509  \n",
       " 38381  0.799284  \n",
       " \n",
       " [38382 rows x 11 columns],\n",
       " {'avg_energy': {'min': 0.029, 'max': 1.5369999, 'std': 0.17910181663372435},\n",
       "  'visibility': {'min': 0.15471755012131883,\n",
       "   'max': 16.4892185239708,\n",
       "   'std': 2.9877044541423623},\n",
       "  'temperature': {'min': -5.64,\n",
       "   'max': 32.46018176771919,\n",
       "   'std': 5.92927874644707},\n",
       "  'dewPoint': {'min': -9.98, 'max': 19.88, 'std': 5.162502432777911},\n",
       "  'pressure': {'min': 975.7095417653958,\n",
       "   'max': 1043.32,\n",
       "   'std': 11.434769423414842},\n",
       "  'windSpeed': {'min': 0.008711021305886649,\n",
       "   'max': 14.975826252715649,\n",
       "   'std': 2.034641096777125},\n",
       "  'humidity': {'min': 0.23,\n",
       "   'max': 1.0056940832170684,\n",
       "   'std': 0.14077533155394165}})"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, _ = getData()\n",
    "df.to_csv(path_or_buf=\"../normalized_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
