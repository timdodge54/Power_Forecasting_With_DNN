{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def PrecipTypeToVal(precip_type):\n",
    "    if precip_type == 'rain':\n",
    "        return 0\n",
    "    elif precip_type == 'snow':\n",
    "        return 1\n",
    "    else:\n",
    "        raise RuntimeError('that is not a good precip type')\n",
    "    \n",
    "def ValToPrecipType(precip_type):\n",
    "    if precip_type == 0:\n",
    "        return 'rain'\n",
    "    elif precip_type == 1:\n",
    "        return 'snow'\n",
    "    else:\n",
    "        raise RuntimeError('that is not a good precip type value')\n",
    "\n",
    "def getData(data_dir = '../data/'):\n",
    "    # Load data \n",
    "    holidays_df       = pd.read_csv(data_dir + 'uk_bank_holidays.csv')\n",
    "    weather_hourly_df = pd.read_csv(data_dir + 'weather_hourly_darksky.csv')\n",
    "    by_meter_df       = pd.read_csv(data_dir + 'informations_households.csv')\n",
    "\n",
    "    half_hour_power_df = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_0.csv\")\n",
    "    for block_it in range(1,112):\n",
    "        half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
    "        half_hour_power_df = pd.concat([half_hour_power_block], ignore_index=True)\n",
    "    holidays_df = holidays_df.drop('Type', axis=1)\n",
    "    holidays_df['Bank holidays'] = pd.to_datetime(holidays_df['Bank holidays'], format='%Y-%m-%d', utc=True)\n",
    "    weather_hourly_df = weather_hourly_df.rename(columns={\"time\": \"timestamp\"})\n",
    "    weather_hourly_df = weather_hourly_df.drop(['icon', 'windBearing', 'apparentTemperature', 'summary'], axis=1)\n",
    "    weather_hourly_df['timestamp'] = pd.to_datetime(weather_hourly_df['timestamp'], utc=True)\n",
    "    by_meter_df = by_meter_df.drop(['stdorToU', 'Acorn', 'file'], axis=1)\n",
    "    half_hour_power_df = half_hour_power_df.rename(columns={\"tstp\": \"timestamp\"})\n",
    "    half_hour_power_df['timestamp'] = pd.to_datetime(half_hour_power_df['timestamp'], utc=True)\n",
    "    half_hour_power_df = half_hour_power_df[half_hour_power_df['energy(kWh/hh)'] != 'Null']\n",
    "    half_hour_power_df['energy(kWh/hh)'] = half_hour_power_df['energy(kWh/hh)'].astype('float')\n",
    "\n",
    "    # Get time vec\n",
    "    weather_hourly_df = weather_hourly_df.sort_values(by='timestamp')\n",
    "    start_time = weather_hourly_df['timestamp'].iloc[0]\n",
    "    end_time = weather_hourly_df['timestamp'].iloc[-1]\n",
    "    iterated_time = start_time + timedelta(minutes=30)\n",
    "    all_needed_times = [copy.deepcopy(iterated_time)]\n",
    "    while iterated_time < end_time:\n",
    "        iterated_time = iterated_time + timedelta(minutes=30)\n",
    "        all_needed_times.append(copy.deepcopy(iterated_time))\n",
    "    time_df = pd.DataFrame({'timestamp': all_needed_times})\n",
    "\n",
    "    # Interpolate weather data\n",
    "    weather_half_hour_df = pd.merge(time_df, weather_hourly_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df.sort_values(by='timestamp', inplace=True)\n",
    "    weather_half_hour_df['precipType'].fillna(method='ffill', inplace=True)\n",
    "    weather_half_hour_df['precipType'].fillna(method='bfill', inplace=True)\n",
    "    for col_it in ['temperature', 'dewPoint', 'pressure', 'windSpeed', 'humidity', 'visibility']:\n",
    "        weather_half_hour_df[col_it].interpolate(method='quadratic', inplace=True)\n",
    "        weather_half_hour_df[col_it].fillna(method='ffill', inplace=True)\n",
    "        weather_half_hour_df[col_it].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Replace precipType with index values\n",
    "    weather_half_hour_df['precipType'] = weather_half_hour_df['precipType'].apply(lambda x: PrecipTypeToVal(x))\n",
    "\n",
    "    # Add holidays \n",
    "    weather_half_hour_df = weather_half_hour_df.merge(holidays_df, left_on = 'timestamp', right_on = 'Bank holidays', how = 'left')\n",
    "    weather_half_hour_df['Bank holidays'] = np.where(weather_half_hour_df['Bank holidays'].isna(), 0, 1)\n",
    "\n",
    "    # Put it all together\n",
    "    housecount   = half_hour_power_df.groupby('timestamp')[['LCLid']].nunique().sort_values(by='timestamp').astype('float')\n",
    "    total_energy = half_hour_power_df.groupby('timestamp')[['energy(kWh/hh)']].sum().sort_values(by='timestamp').astype('float')\n",
    "\n",
    "    weather_half_hour_df = pd.merge(housecount, weather_half_hour_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df = weather_half_hour_df.rename(columns={\"LCLid\": \"num_houses\"})\n",
    "    \n",
    "    weather_half_hour_df = pd.merge(total_energy, weather_half_hour_df, on='timestamp', how='left')\n",
    "    weather_half_hour_df = weather_half_hour_df.rename(columns={\"energy(kWh/hh)\": \"total_energy\"})\n",
    "    \n",
    "    weather_half_hour_df.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "\n",
    "    output = pd.DataFrame(data={'timestamp': weather_half_hour_df['timestamp'],\n",
    "                                'avg_energy': weather_half_hour_df['total_energy'] / weather_half_hour_df['num_houses'],\n",
    "                                'num_houses': weather_half_hour_df['num_houses'],\n",
    "                                'is_holiday': weather_half_hour_df['Bank holidays'],\n",
    "                                'visibility': weather_half_hour_df['visibility'],\n",
    "                                'temperature': weather_half_hour_df['temperature'],\n",
    "                                'dewPoint': weather_half_hour_df['dewPoint'],\n",
    "                                'pressure': weather_half_hour_df['pressure'],\n",
    "                                'windSpeed': weather_half_hour_df['windSpeed'],\n",
    "                                'precipType': weather_half_hour_df['precipType'],\n",
    "                                'humidity': weather_half_hour_df['humidity']})\n",
    "    output.dropna(axis=0, inplace=True)\n",
    "\n",
    "    # Normalize \n",
    "    normalization_cols = [i for i in output.columns.tolist() if i not in ['timestamp', 'precipType', 'num_houses', 'is_holiday']]\n",
    "    normalization_vals = {}\n",
    "    for col_name in normalization_cols:\n",
    "        normalization_vals[col_name] = {}\n",
    "        normalization_vals[col_name]['min'] = output[col_name].min()\n",
    "        normalization_vals[col_name]['max'] = output[col_name].max()\n",
    "        normalization_vals[col_name]['std'] = output[col_name].std()\n",
    "    normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "    output[normalization_cols] = normalizer.fit_transform(output[normalization_cols])\n",
    "\n",
    "    return output, normalization_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n",
      "/tmp/ipykernel_118582/3246606967.py:48: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  half_hour_power_block = pd.read_csv(data_dir + \"halfhourly_dataset/halfhourly_dataset/block_\" + str(block_it) + \".csv\")\n"
     ]
    }
   ],
   "source": [
    "df, _ = getData()\n",
    "df.to_csv(path_or_buf=\"../normalized_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
